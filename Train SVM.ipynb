{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from data_processing import preprocess_data, get_dictionary, featurize_data\n",
    "from cross_validation import cross_validation, evaluate_classifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "import pickle\n",
    "import nltk\n",
    "import pandas as pd\n",
    "import gensim\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "import os\n",
    "from nltk.tokenize import word_tokenize\n",
    "from gensim.test.test_doc2vec import ConcatenatedDoc2Vec\n",
    "from pathlib import Path\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_path = 'datasets/data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def preprocess_data(datapath):\n",
    "    X = []\n",
    "    y = []\n",
    "    filenames = []\n",
    "    for temp,j,_ in os.walk(datapath):\n",
    "            for f in sorted(os.listdir(temp)):\n",
    "                if f.endswith('.tag'):\n",
    "                    with open(os.path.join(temp, f), 'r') as demo:\n",
    "                        x = []\n",
    "                        for l in demo:\n",
    "                            if l == '\\n':\n",
    "                                continue\n",
    "                            token, _ = l.split('\\t')\n",
    "                            x.append(token)\n",
    "                    label = 1 if os.path.basename(os.path.normpath(temp)) == 'POS' else 0\n",
    "                    filenames.append(f)\n",
    "                    X.append(x)\n",
    "                    y.append(label)\n",
    "    return np.array(X), np.array(y), filenames                 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X, y, filenames = preprocess_data(data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "k = 10\n",
    "folds = [ [] for i in range(k)]\n",
    "for index in range(len(y)):\n",
    "    folds[index%k].append(index)\n",
    "test_idxs = folds[0]\n",
    "train_idxs = list(set(np.concatenate(folds)) - set(test_idxs))\n",
    "X_train = X[train_idxs]\n",
    "y_train = y[train_idxs]\n",
    "X_test = X[test_idxs]\n",
    "y_test = y[test_idxs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def cross_validation(X, y, model, k=9):\n",
    "\n",
    "    folds = [ [] for i in range(k)]\n",
    "    for index in range(len(y)):\n",
    "        folds[index%k].append(index)\n",
    "\n",
    "    y_pred = []\n",
    "    y_val_labels = []        \n",
    "    accuracies = []\n",
    "\n",
    "        \n",
    "    for val in range(k):\n",
    "        \n",
    "        val_idxs = folds[val]\n",
    "        train_idxs = list(set(np.concatenate(folds)) - set(val_idxs))\n",
    "        X_train = X[train_idxs]\n",
    "        y_train = y[train_idxs]\n",
    "        X_val = X[val_idxs]\n",
    "        y_val = y[val_idxs]\n",
    "\n",
    "        model.fit(X_train, y_train)\n",
    "        pred = model.predict(X_val)\n",
    "        y_pred = np.concatenate([y_pred, pred])\n",
    "        y_val_labels = np.concatenate([y_val_labels, y_val])\n",
    "        accuracies.append((pred == y_val).mean())\n",
    "\n",
    "    print(\"Average accuracy is {}(variance {})\\n\".format(np.mean(accuracies), np.var(accuracies)))\n",
    "\n",
    "    return y_pred, y_val_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "doc_embeddings = []\n",
    "for f in os.listdir(\"doc2vec\"):\n",
    "    if f.endswith('.model'):\n",
    "        doc_embeddings.append(\"doc2vec/\"+f)\n",
    "\n",
    "print(doc_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "C_range = np.logspace(-2, 10, 10)\n",
    "gamma_range = np.logspace(-9, 3, 13)\n",
    "print(C_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "SVM_with_embeddings_param_grid = {\n",
    "                                    'doc_embeddings': doc_embeddings, \n",
    "                                    'svm_kernel' : ['rbf', 'linear', 'poly'],\n",
    "                                    'C': [0.1, 1, 10],\n",
    "                                    'gamma': [1e-3, 1e-4]\n",
    "                                 }\n",
    "\n",
    "grid = ParameterGrid(SVM_with_embeddings_param_grid)\n",
    "for params in grid:\n",
    "    print(params)\n",
    "    \n",
    "    \n",
    "    doc2vec = Doc2Vec.load(params['doc_embeddings'])\n",
    "    X_features = np.array([doc2vec.infer_vector(x) for x in X_train])\n",
    "    if params['svm_kernel'] != 'linear':\n",
    "        model = SVC(kernel=params['svm_kernel'], C=params['C'], gamma=params['gamma'])\n",
    "    else:\n",
    "        model = SVC(kernel=params['svm_kernel'], C=params['C'])\n",
    "\n",
    "\n",
    "    total_y_pred, total_y_test= cross_validation(X_features, y_train, model)\n",
    "    \n",
    "    model_results = {}\n",
    "    model_results['predictions'] = total_y_pred\n",
    "    model_results['labels'] = total_y_test\n",
    "\n",
    "    pickle.dump(model_results, open(\"svm/{}_{}_{}.pkl\".format(params['svm_kernel'], params['C'], params['gamma'], Path(params['doc_embeddings']).stem), 'wb'))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "SVM_with_embeddings_param_grid = {\n",
    "                                    'svm_kernel' : ['rbf', 'linear', 'poly'],\n",
    "                                    'C': [0.1, 1, 10],\n",
    "                                    'gamma': [1e-3, 1e-4]\n",
    "                                 }\n",
    "\n",
    "grid = ParameterGrid(SVM_with_embeddings_param_grid)\n",
    "for params in grid:\n",
    "    print(params)\n",
    "    \n",
    "    \n",
    "    doc2vec1 = Doc2Vec.load(\"doc2vec/dbow_dm_model1.model\")\n",
    "    doc2vec2 = Doc2Vec.load(\"doc2vec/dbow_dm_model2.model\")\n",
    "    dbow_dm = ConcatenatedDoc2Vec([doc2vec1, doc2vec2])\n",
    "\n",
    "\n",
    "\n",
    "    X_features = np.array([dbow_dm.infer_vector(x) for x in X_train])\n",
    "    if params['svm_kernel'] != 'linear':\n",
    "        model = SVC(kernel=params['svm_kernel'], C=params['C'], gamma=params['gamma'])\n",
    "    else:\n",
    "        model = SVC(kernel=params['svm_kernel'], C=params['C'])\n",
    "\n",
    "\n",
    "    total_y_pred, total_y_test= cross_validation(X_features, y_train, model)\n",
    "    \n",
    "    model_results = {}\n",
    "    model_results['predictions'] = total_y_pred\n",
    "    model_results['labels'] = total_y_test\n",
    "\n",
    "    #pickle.dump(model_results, open(\"svm/{}_{}_{}.pkl\".format(params['svm_kernel'], params['C'], params['gamma'], Path(params['doc_embeddings']).stem), 'wb'))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#dm\n",
    "doc2vec = Doc2Vec.load('doc2vec/10_100_15_1_2_0_15.model')\n",
    "X_test_final = np.array([doc2vec.infer_vector(x) for x in X_test])\n",
    "X_features = np.array([doc2vec.infer_vector(x) for x in X_train])\n",
    "model = SVC(kernel='rbf', C=10, gamma=0.001)\n",
    "model.fit(X_features, y_train)\n",
    "y_pred_dm = np.array(model.predict(X_test_final))\n",
    "print(((y_pred_dm == np.array(y_test)).mean()))\n",
    "\n",
    "\n",
    "#dbow\n",
    "doc2vec = Doc2Vec.load(\"doc2vec/10_200_10_0_2_0_5.model\")\n",
    "X_test_final = np.array([doc2vec.infer_vector(x) for x in X_test])\n",
    "X_features = np.array([doc2vec.infer_vector(x) for x in X_train])\n",
    "model = SVC(kernel='rbf', C=10, gamma=0.001)\n",
    "model.fit(X_features, y_train)\n",
    "y_pred_dbow = np.array(model.predict(X_test_final))\n",
    "print(((y_pred_dbow == np.array(y_test)).mean()))\n",
    "\n",
    "\n",
    "#for dm + dbow\n",
    "doc2vec1 = Doc2Vec.load(\"doc2vec/dbow_dm_model1.model\")\n",
    "doc2vec2 = Doc2Vec.load(\"doc2vec/dbow_dm_model2.model\")\n",
    "dbow_dm = ConcatenatedDoc2Vec([doc2vec1, doc2vec2])\n",
    "\n",
    "X_features = np.array([dbow_dm.infer_vector(x) for x in X_train])\n",
    "X_test_final = np.array([dbow_dm.infer_vector(x) for x in X_test])\n",
    "model = SVC(kernel='linear', C=0.1, gamma=0.001)\n",
    "model.fit(X_features, y_train)\n",
    "y_pred_pv_concat = np.array(model.predict(X_test_final))\n",
    "print(((y_pred_pv_concat == np.array(y_test)).mean()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train_ = []\n",
    "X_test_ = []\n",
    "for x in X_train:\n",
    "    review = ' '.join(x)\n",
    "    X_train_.append(review)\n",
    "for x in X_test:\n",
    "    review = ' '.join(x)\n",
    "    X_test_.append(review)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### bit more efficient than my own implementation, speed up things"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(ngram_range=(1, 1), token_pattern=r'\\b\\w+\\b', min_df=1)\n",
    "X_train_grams = vectorizer.fit_transform(X_train_)\n",
    "X_test_grams = vectorizer.transform(X_test_)\n",
    "model = SVC(kernel='linear', C=10, gamma=0.0001)\n",
    "model.fit(X_train_grams, y_train)\n",
    "y_pred_uni_freq = np.array(model.predict(X_test_grams))\n",
    "print(((y_pred_uni_freq == np.array(y_test)).mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(ngram_range=(2, 2), token_pattern=r'\\b\\w+\\b', min_df=1)\n",
    "X_train_grams = vectorizer.fit_transform(X_train_)\n",
    "X_test_grams = vectorizer.transform(X_test_)\n",
    "model = SVC(kernel='linear',C=0.1, gamma=0.0001)\n",
    "model.fit(X_features, y_train)\n",
    "y_pred_bi_freq = np.array(model.predict(X_test_final))\n",
    "print(((y_pred_bi_freq == np.array(y_test)).mean()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(ngram_range=(1, 2), token_pattern=r'\\b\\w+\\b', min_df=1)\n",
    "X_train_grams = vectorizer.fit_transform(X_train_)\n",
    "X_test_grams = vectorizer.transform(X_test_)\n",
    "model = SVC(kernel='linear', C=0.1, gamma=0.001)\n",
    "model.fit(X_features, y_train)\n",
    "y_pred_freq_concat = np.array(model.predict(X_test_final))\n",
    "print(((y_pred_freq_concat == np.array(y_test)).mean()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(ngram_range=(1, 1), token_pattern=r'\\b\\w+\\b', min_df=1, binary = True)\n",
    "X_train_grams = vectorizer.fit_transform(X_train_)\n",
    "X_test_grams = vectorizer.transform(X_test_)\n",
    "model = SVC(kernel='linear', C=10, gamma=0.0001)\n",
    "model.fit(X_features, y_train)\n",
    "y_pred_uni_bin = np.array(model.predict(X_test_final))\n",
    "print(((y_pred_uni_bin == np.array(y_test)).mean()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(ngram_range=(2, 2), token_pattern=r'\\b\\w+\\b', min_df=1, binary = True)\n",
    "X_train_grams = vectorizer.fit_transform(X_train_)\n",
    "X_test_grams = vectorizer.transform(X_test_)\n",
    "model = SVC(kernel='linear', C=0.1, gamma=0.0001)\n",
    "model.fit(X_features, y_train)\n",
    "y_pred_bi_bin = np.array(model.predict(X_test_final))\n",
    "print(((y_pred_bi_bin == np.array(y_test)).mean()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(ngram_range=(1, 2), token_pattern=r'\\b\\w+\\b', min_df=1, binary = True)\n",
    "X_train_grams = vectorizer.fit_transform(X_train_)\n",
    "X_test_grams = vectorizer.transform(X_test_)\n",
    "model = SVC(kernel='linear', C=1, gamma=0.001)\n",
    "model.fit(X_features, y_train)\n",
    "y_pred_concat_bin = np.array(model.predict(X_test_final))\n",
    "print(((y_pred == np.array(y_test)).mean()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "models = [y_pred_dm, y_pred_dbow, y_pred_pv_concat,\n",
    "            y_pred_uni_freq, y_pred_bi_freq, y_pred_freq_concat, \n",
    "              y_pred_uni_bin, y_pred_bi_bin, y_pred_concat_bin]\n",
    "\n",
    "\n",
    "    \n",
    "for models in itertools.combinations(models, 2):\n",
    "    permutation_test_(models[0], models[1], y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def permutation_test_(y1, y2, y_true):\n",
    "    y1 = [1 if y1[i] == y_true[i] else 0 for i in range(len(y_true))]\n",
    "    y2 = [1 if y2[i] == y_true[i] else 0 for i in range(len(y_true))]                  \n",
    "    y1_test = y1 == y_true\n",
    "    y2_test = y2 == y_true\n",
    "    samples = 0\n",
    "    r=5000\n",
    "    for i in range(r):\n",
    "        flips = np.random.randint(2, size=len(y1))\n",
    "        y1_t = [y1[j] if flips[j] == 0 else y2[j] for j in range(len(y1))]\n",
    "        y2_t = [y2[j] if flips[j] == 0 else y1[j] for j in range(len(y1))]\n",
    "        diff = np.abs(np.mean(y1_t) - np.mean(y2_t))\n",
    "        if diff >= np.abs(np.mean(y1) - np.mean(y2)):\n",
    "            samples += 1\n",
    "    print((greater_samples + 1.0) / (r + 1.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "permutation_test_(total_y_pred_dm, total_y_pred_bigram, total_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "permutation_test_(total_y_pred_dm, total_y_pred_bigram, total_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "SVM_with_bow_param_grid = {\n",
    "                                    'svm_kernel' : ['rbf', 'linear', 'poly'],\n",
    "                                    'unigrams': [True, False], \n",
    "                                    'bigrams' : [True, False],\n",
    "                                    'C': [0.1, 1, 10],\n",
    "                                    'gamma': [1e-3, 1e-4]\n",
    "                          }\n",
    "grid = ParameterGrid(SVM_with_bow_param_grid)\n",
    "for params in grid:\n",
    "    print(params)\n",
    "    if params['svm_kernel'] != 'linear':\n",
    "        model = SVC(kernel=params['svm_kernel'], C=params['C'], gamma=params['gamma'])\n",
    "    else:\n",
    "        model = SVC(kernel=params['svm_kernel'], C=params['C'])\n",
    "\n",
    "        total_y_pred, total_y_test= cross_validation(X_train, y_train, model)\n",
    "\n",
    "    model_results = {}\n",
    "    model_results['predictions'] = total_y_pred\n",
    "    model_results['labels'] = total_y_test\n",
    "    #pickle.dump(model_results, open(\"svm/{}_{}_{}_{}.pkl\".format(params['svm_kernel'], params['C'], params['gamma'], params['unigrams'], params['bigrams']), 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_accuracies = []\n",
    "\n",
    "for f in os.listdir(\"svm\"):\n",
    "    if f.endswith('.pkl'):\n",
    "        with (open(\"svm/\"+f, \"rb\")) as openfile:\n",
    "            model_accuracies.append(pickle.load(openfile))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model_accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "type(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "doc2vec = Doc2Vec.load(\"doc2vec/10_200_10_0_2_0_5.model\")\n",
    "X_features = np.array([doc2vec.infer_vector(x) for x in X_train])\n",
    "X_test_final = np.array([doc2vec.infer_vector(x) for x in X_test])\n",
    "\n",
    "\n",
    "model = SVC(kernel='rbf', C=10, gamma=0.001)\n",
    "model.fit(X_features, y_train)\n",
    "y_pred = np.array(model.predict(X_test_final))\n",
    "print(((y_pred == np.array(y_test)).mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test = np.nonzero(np.equal(y_pred,y_test)==False)\n",
    "print(test)\n",
    "print(len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test = np.nonzero(np.equal(y_pred,y_test)==False)\n",
    "print(test)\n",
    "print(len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "test2 = np.array(test_idxs)\n",
    "for i in test2:\n",
    "    print(filenames[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "X_test[test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "counter = 0\n",
    "for x in X_val[test]:\n",
    "    for i in x:\n",
    "        if i =='not' or i=='but':\n",
    "            counter += 1\n",
    "            break\n",
    "\n",
    "print(counter)\n",
    "               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "negation = []\n",
    "labels = []\n",
    "with open(\"datasets/sentiment_negation.txt\", 'r') as demo:\n",
    "    for l in demo:\n",
    "        text = nltk.word_tokenize(l[2:])\n",
    "        text = [x.lower() for x in text]\n",
    "        negation.append(text)\n",
    "        if l[0] == '0' or l[0] == '1':\n",
    "            labels.append(0)\n",
    "        else:\n",
    "            labels.append(1)\n",
    "print(negation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_val_final = np.array([doc2vec.infer_vector(x) for x in negation])\n",
    "y_pred = model.predict(X_val_final)\n",
    "print(y_pred)\n",
    "print(labels)\n",
    "print(((y_pred == labels).mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deployment Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('datasets/new_movies.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.ix[:,0].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_deployment = df.ix[:,1]\n",
    "y_deployment = df.ix[:,0].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "new = X_deployment.tolist()\n",
    "reviews = []\n",
    "for item in new:\n",
    "    text = nltk.word_tokenize(item)\n",
    "    text = [x.lower() for x in text]\n",
    "    reviews.append(text)\n",
    "print(len(reviews))\n",
    "print(len(y_deployment))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "doc2vec = Doc2Vec.load('doc2vec/10_200_10_0_2_0_5.model')\n",
    "X_test_deployment = np.array([doc2vec.infer_vector(x) for x in reviews])\n",
    "y_pred = model.predict(X_test_deployment)\n",
    "print(((y_pred == y_deployment).mean()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
