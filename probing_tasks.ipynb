{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled9.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "dMW5tMG7Hm3A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import absolute_import, division, unicode_literals\n",
        "\n",
        "import sys\n",
        "import logging\n",
        "from gensim.models.doc2vec import Doc2Vec\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "import nltk \n",
        "\n",
        "logging.basicConfig(format='%(asctime)s : %(message)s', level=logging.DEBUG)\n",
        "\n",
        "doc2vec = Doc2Vec.load(\"best_dbowmodel.model\")\n",
        "\n",
        "# Set PATHs\n",
        "PATH_TO_SENTEVAL = '../'\n",
        "PATH_TO_DATA = '../data'\n",
        "\n",
        "# import SentEval\n",
        "sys.path.insert(0, PATH_TO_SENTEVAL)\n",
        "import senteval\n",
        "\n",
        "def prepare(params, samples):\n",
        "    return\n",
        "\n",
        "def batcher(params, batch):\n",
        "    batch = [' '.join(sent) if sent != [] else '.' for sent in batch]\n",
        "    sent_emb = []\n",
        "    for x in batch:\n",
        "        sent_emb.append(word_tokenize(x))\n",
        "    embeddings = [doc2vec.infer_vector(x) for x in sent_emb]\n",
        "    return embeddings\n",
        "\n",
        "#Reproduce paper results\n",
        "params = {'task_path': PATH_TO_DATA, 'usepytorch': True, 'kfold': 10}\n",
        "params['classifier'] = {'nhid': 0, 'optim': 'adam', 'batch_size': 64,\n",
        "                                 'tenacity': 5, 'epoch_size': 4}\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    se = senteval.engine.SE(params, batcher, prepare)\n",
        "    transfer_tasks = ['Length', 'WordContent', 'Depth', 'TopConstituents','BigramShift', 'Tense', 'SubjNumber', 'ObjNumber', 'OddManOut', 'CoordinationInversion']\n",
        "    results = se.eval(transfer_tasks)\n",
        "    print(results)\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}